# School Data Freshness Monitoring Workflow
#
# Runs weekly to:
# 1. Fetch latest school data from external source
# 2. Run ETL to process and validate data
# 3. Generate data quality report
# 4. Alert if data quality degrades
#
# Schedule: Weekly (Sunday 00:00 UTC)
# Manual trigger: workflow_dispatch available

name: Data Freshness Monitoring

on:
  schedule:
    - cron: '0 0 * * 0'  # Every Sunday at 00:00 UTC
  workflow_dispatch:
    inputs:
      force_refresh:
        description: 'Force data refresh even if fresh'
        required: false
        default: 'false'
        type: choice
        options:
          - 'true'
          - 'false'

permissions:
  contents: write
  issues: write
  pull-requests: write

env:
  DATA_MAX_AGE_DAYS: 7

jobs:
  check-freshness:
    name: Check Data Freshness
    runs-on: ubuntu-slim
    outputs:
      is-fresh: ${{ steps.check.outputs.is-fresh }}
      days-since-update: ${{ steps.check.outputs.days-since-update }}
      current-record-count: ${{ steps.check.outputs.record-count }}
    steps:
      - name: Checkout
        uses: actions/checkout@v5

      - name: Check data freshness
        id: check
        run: |
          if [ ! -f "data/schools.csv" ]; then
            echo "is-fresh=false" >> $GITHUB_OUTPUT
            echo "days-since-update=999" >> $GITHUB_OUTPUT
            echo "record-count=0" >> $GITHUB_OUTPUT
            exit 0
          fi

          # Get the most recent updated_at from schools.csv
          LAST_UPDATE=$(tail -n +2 data/schools.csv | cut -d',' -f12 | sort -r | head -1)
          
          if [ -z "$LAST_UPDATE" ]; then
            echo "is-fresh=false" >> $GITHUB_OUTPUT
            echo "days-since-update=999" >> $GITHUB_OUTPUT
            echo "record-count=0" >> $GITHUB_OUTPUT
            exit 0
          fi

          # Calculate days since last update
          LAST_UPDATE_EPOCH=$(date -d "$LAST_UPDATE" +%s 2>/dev/null || echo "0")
          CURRENT_EPOCH=$(date +%s)
          DAYS_SINCE=$(( (CURRENT_EPOCH - LAST_UPDATE_EPOCH) / 86400 ))

          echo "days-since-update=$DAYS_SINCE" >> $GITHUB_OUTPUT
          echo "record-count=$(tail -n +2 data/schools.csv | wc -l)" >> $GITHUB_OUTPUT

          if [ $DAYS_SINCE -lt ${{ env.DATA_MAX_AGE_DAYS }} ]; then
            echo "is-fresh=true" >> $GITHUB_OUTPUT
            echo "Data is fresh ($DAYS_SINCE days old)"
          else
            echo "is-fresh=false" >> $GITHUB_OUTPUT
            echo "Data is stale ($DAYS_SINCE days old)"
          fi

  fetch-and-etl:
    name: Fetch Data & Run ETL
    needs: check-freshness
    if: needs.check-freshness.outputs.is-fresh == 'false' || github.event.inputs.force_refresh == 'true'
    runs-on: ubuntu-slim
    outputs:
      record-count: ${{ steps.etl.outputs.record-count }}
      quality-score: ${{ steps.etl.outputs.quality-score }}
      has-changes: ${{ steps.etl.outputs.has-changes }}
    steps:
      - name: Checkout
        uses: actions/checkout@v5

      - name: Setup Node.js
        uses: actions/setup-node@v5
        with:
          node-version: '20'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Fetch latest school data
        id: fetch
        run: |
          # Clone or update the external data repository
          EXTERNAL_DIR="external-data"
          
          if [ -d "$EXTERNAL_DIR" ]; then
            cd $EXTERNAL_DIR
            git pull origin main --quiet || true
            cd ..
          else
            # Clone the daftar-sekolah-indonesia repository
            # Note: Using a placeholder URL - replace with actual source
            git clone --depth 1 https://github.com/玩家们/daftar-sekolah-indonesia.git $EXTERNAL_DIR 2>/dev/null || {
              echo "External data source not available, using existing data"
              echo "has-changes=false" >> $GITHUB_OUTPUT
              exit 0
            }
          fi

          # Find the CSV file in external data
          RAW_CSV=$(find $EXTERNAL_DIR -name "*.csv" -type f | head -1)
          
          if [ -n "$RAW_CSV" ]; then
            cp "$RAW_CSV" external/raw.csv
            echo "Fetched data from $RAW_CSV"
          else
            echo "No CSV found in external data"
            echo "has-changes=false" >> $GITHUB_OUTPUT
            exit 0
          fi

      - name: Run ETL
        id: etl
        run: |
          npm run etl 2>&1 || {
            echo "ETL failed - checking if data exists"
            if [ -f "data/schools.csv" ]; then
              echo "Using existing schools.csv"
            else
              exit 1
            fi
          }

          # Get record count
          RECORD_COUNT=$(tail -n +2 data/schools.csv | wc -l)
          echo "record-count=$RECORD_COUNT" >> $GITHUB_OUTPUT

          # Calculate quality score (based on coordinate completeness and NPSN uniqueness)
          # This is a simplified metric - the ETL already outputs detailed metrics
          VALID_COORDS=$(awk -F',' 'NR>1 && $10!="" && $11!="" {count++} END {print+count}' data/schools.csv)
          QUALITY_SCORE=$(echo "scale=2; ($VALID_COORDS / $RECORD_COUNT) * 100" | bc 2>/dev/null || echo "100")
          echo "quality-score=$QUALITY_SCORE" >> $GITHUB_OUTPUT

          # Check if there are actual changes (simple heuristic)
          if [ -n "${{ needs.check-freshness.outputs.current-record-count }}" ]; then
            if [ "$RECORD_COUNT" != "${{ needs.check-freshness.outputs.current-record-count }}" ]; then
              echo "has-changes=true" >> $GITHUB_OUTPUT
            else
              echo "has-changes=false" >> $GITHUB_OUTPUT
            fi
          else
            echo "has-changes=true" >> $GITHUB_OUTPUT
          fi

      - name: Commit updated data
        if: steps.etl.outputs.has-changes == 'true'
        run: |
          git config --global user.name "Data Bot"
          git config --global user.email "data-bot@sekolah-pseo.github.io"
          
          git add data/schools.csv
          git diff --cached --quiet || {
            git commit -m "chore(data): update school data - $(date -u +%Y-%m-%d)"
            git push origin main
          }

  report-quality:
    name: Data Quality Report
    needs: [check-freshness, fetch-and-etl]
    if: always()
    runs-on: ubuntu-slim
    steps:
      - name: Checkout
        uses: actions/checkout@v5

      - name: Generate quality summary
        id: quality
        run: |
          if [ -f "data/schools.csv" ]; then
            TOTAL=$(tail -n +2 data/schools.csv | wc -l)
            WITH_COORDS=$(awk -F',' 'NR>1 && $10!="" && $11!="" {count++} END {print+count}' data/schools.csv)
            WITH_ADDRESS=$(awk -F',' 'NR>1 && $5!="" {count++} END {print+count}' data/schools.csv)
            
            echo "## Data Quality Report" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "| Metric | Value |" >> $GITHUB_STEP_SUMMARY
            echo "|--------|-------|" >> $GITHUB_STEP_SUMMARY
            echo "| Total Records | $TOTAL |" >> $GITHUB_STEP_SUMMARY
            echo "| Records with Coordinates | $WITH_COORDS |" >> $GITHUB_STEP_SUMMARY
            echo "| Records with Address | $WITH_ADDRESS |" >> $GITHUB_STEP_SUMMARY
            echo "| Last Check | $(date -u +%Y-%m-%dT%H:%M:%SZ) |" >> $GITHUB_STEP_SUMMARY
            
            if [ "${{ needs.check-freshness.outputs.days-since-update }}" != "999" ]; then
              echo "| Data Age | ${{ needs.check-freshness.outputs.days-since-update }} days |" >> $GITHUB_STEP_SUMMARY
            fi
          fi

      - name: Alert on stale data
        if: needs.check-freshness.outputs.is-fresh == 'false'
        run: |
          # Create an issue if data is stale
          gh issue create \
            --title "Data Staleness Alert: ${{ needs.check-freshness.outputs.days-since-update }} days old" \
            --body "## Data Staleness Alert

The school data is **${{ needs.check-freshness.outputs.days-since-update }} days old** (threshold: ${{ env.DATA_MAX_AGE_DAYS }} days).

### Current Status
- Record count: ${{ needs.check-freshness.outputs.current-record-count }}
- Last update: ${{ needs.check-freshness.outputs.days-since-update }} days ago

### Action Required
Please run the ETL process to fetch latest data, or the scheduled workflow will update automatically.

---
*Generated by Data Freshness Monitoring*"
            --label "data,priority:P3" 2>/dev/null || echo "Issue creation skipped (may already exist)"

      - name: Success notification
        if: needs.check-freshness.outputs.is-fresh == 'true'
        run: echo "✅ Data is fresh (${{ needs.check-freshness.outputs.days-since-update }} days old)"
